{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c299790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas tqdm faiss-cpu langchain langchain-community langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7092615",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH = \"tmdb_labeled.parquet\"   # upload this file to Colab\n",
    "INDEX_DIR = \"tmdb_index\"\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "def row_to_block(row: pd.Series) -> str:\n",
    "    cols = [\n",
    "        'id','name','number_of_seasons','number_of_episodes','original_language',\n",
    "        'vote_count','vote_average','overview','adult','backdrop_path','first_air_date',\n",
    "        'last_air_date','homepage','in_production','original_name','popularity',\n",
    "        'poster_path','type','status','tagline','genres','created_by','languages',\n",
    "        'networks','origin_country','spoken_languages','production_companies',\n",
    "        'production_countries','episode_run_time','is_popular','is_long_running'\n",
    "    ]\n",
    "    lines = []\n",
    "    for c in cols:\n",
    "        if c in row:\n",
    "            lines.append(f\"{c}: {row[c]}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def build_index(force_rebuild=False):\n",
    "    os.makedirs(INDEX_DIR, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(os.path.join(INDEX_DIR, \"index.faiss\")) and not force_rebuild:\n",
    "        print(f\"‚úÖ Using existing FAISS index at {INDEX_DIR}\")\n",
    "        return\n",
    "\n",
    "    print(\"‚öôÔ∏è Building new FAISS index...\")\n",
    "    df = pd.read_parquet(SOURCE_PATH)\n",
    "\n",
    "    docs_text = [row_to_block(r) for _, r in tqdm(df.iterrows(), total=len(df), desc=\"üìÑ Converting rows\")]\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "    docs = splitter.create_documents(docs_text)\n",
    "\n",
    "    print(\"üî¢ Generating embeddings...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
    "\n",
    "    vs = FAISS.from_documents(tqdm(docs, desc=\"‚ö° Embedding docs\"), embeddings)\n",
    "    vs.save_local(INDEX_DIR)\n",
    "\n",
    "    print(f\"‚úÖ FAISS index saved to {INDEX_DIR} (chunks: {len(docs)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_index(force_rebuild=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafeb2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
    "vs = FAISS.load_local(INDEX_DIR, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "query = \"Which shows are long running and popular?\"\n",
    "results = vs.similarity_search(query, k=3)\n",
    "\n",
    "for i, res in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i}:\\n{res.page_content[:500]}...\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
